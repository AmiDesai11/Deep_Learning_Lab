{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING THE DATA AND PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width variety  class\n",
      "0           5.1          3.5           1.4          0.2  Setosa      0\n",
      "1           4.9          3.0           1.4          0.2  Setosa      0\n",
      "2           4.7          3.2           1.3          0.2  Setosa      0\n",
      "3           4.6          3.1           1.5          0.2  Setosa      0\n",
      "4           5.0          3.6           1.4          0.2  Setosa      0\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "url = \"iris.csv\"\n",
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"variety\"]\n",
    "data = pd.read_csv(url, names=column_names,skiprows=1)\n",
    "\n",
    "data['class'] = data['variety'].map({'Setosa': 0, 'Versicolor': 1, 'Virginica': 2})\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data.iloc[:, :-2].values\n",
    "y = data['class'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "#Converting output classes to binary matrix\n",
    "y_onehot = encoder.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLITTING THE DATA INTO TRAIN AND TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ASSIGNING THE WEIGHT MATRIX AND BIAS MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 2\n",
    "output_size = 3\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "np.random.seed(0)\n",
    "weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "bias_hidden = np.zeros((1, hidden_size))\n",
    "weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "bias_output = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIGMOID AND DERIVATIVE OF SIGMOID FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PERFORMING BACK PROPOGATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #Calculations in hidden layer\n",
    "    hidden_input = np.dot(X_train, weights_input_hidden) + bias_hidden\n",
    "    hidden_output = sigmoid(hidden_input)\n",
    "    #Calculations in output layer\n",
    "    output_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
    "    output = sigmoid(output_input)\n",
    "\n",
    "    error = y_train - output\n",
    "\n",
    "    delta_output = error * sigmoid_derivative(output)\n",
    "    error_hidden = delta_output.dot(weights_hidden_output.T)\n",
    "    delta_hidden = error_hidden * sigmoid_derivative(hidden_output)\n",
    "\n",
    "    weights_hidden_output += hidden_output.T.dot(delta_output) * learning_rate\n",
    "    bias_output += np.sum(delta_output, axis=0, keepdims=True) * learning_rate\n",
    "    weights_input_hidden += X_train.T.dot(delta_hidden) * learning_rate\n",
    "    bias_hidden += np.sum(delta_hidden, axis=0, keepdims=True) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PERFORMING 2nd FORWARD PASS TO CROSSCHECK OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "hidden_input = np.dot(X_test, weights_input_hidden) + bias_hidden\n",
    "hidden_output = sigmoid(hidden_input)\n",
    "output_input = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
    "predicted_output = sigmoid(output_input)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predicted_output)):\n",
    "    predicted_class = np.argmax(predicted_output[i])\n",
    "    true_class=np.argmax(y_test[i])\n",
    "    if predicted_class == true_class:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = (correct / len(y_test)) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
